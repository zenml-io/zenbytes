{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZenML: Open-source MLOps Framework for reproducible ML pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Test](_assets/Logo/zenml.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import logging as absl_logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "absl_logging.set_verbosity(-10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize ZenML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by initializing ZenML in our directory. We are going to use a local stack to begin with, for simplicity and then transition to other stacks. This can be achieved in code by executing the following block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rm -rf .zen\n",
    "!zenml init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install integrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZenML handles integrations natively, to avoid dependency conflicts, so make sure to use the following command to install the integrations required for this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml integration install sklearn dash evidently mlflow -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add MLFlow Experiment Tracker and Model Deployer to your stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the MLflow experiment tracker\n",
    "!zenml experiment-tracker register mlflow_tracker --type=mlflow\n",
    "\n",
    "# Register the MLflow model deployer\n",
    "!zenml model-deployer register mlflow --type=mlflow\n",
    "\n",
    "# Create a new stack with MLflow experiment tracker and deployer in it\n",
    "!zenml stack register local_with_mlflow -m default -a default -o default -e mlflow_tracker -d mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set it as the active stack\n",
    "!zenml stack set local_with_mlflow\n",
    "!zenml stack describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a simple training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by looking at the definition of a pipeline that we want to build. This will give an overview of what we want to achieve and how we plan on getting there. We'll dive into the details on some of the interesting steps after that.\n",
    "\n",
    "![Pipeline1](_assets/chapter_1/first_pipeline.png \"Pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Steps\n",
    "In the code that follows, you can see that we are defining the various steps of our pipeline. Each step is decorated with `@step`, the main abstraction that is currently available for creating pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import ClassifierMixin\n",
    "\n",
    "from zenml.integrations.sklearn.helpers.digits import (\n",
    "    get_digits,\n",
    ")\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import Output, step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is an import step that downloads the DIGITS dataset and returns four numpy arrays as its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@step\n",
    "def importer() -> Output(\n",
    "    X_train=np.ndarray, X_test=np.ndarray, y_train=np.ndarray, y_test=np.ndarray\n",
    "):\n",
    "    \"\"\"Loads the digits array as normal numpy arrays.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = get_digits()\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then add a Trainer step, that takes the imported data and trains a sklearn classifier on the data. Note that the model is not explicitly saved within the step. Under the hood ZenML uses Materializers to automatically persist the Artifacts that result from each step into the Artifact Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def svc_trainer(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train another simple sklearn classifier for the digits dataset.\"\"\"\n",
    "    model = SVC(gamma=0.001)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we add an Evaluator step that takes as input the test set and the trained model and evaluates some final metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def evaluator(\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    model: ClassifierMixin,\n",
    ") -> float:\n",
    "    \"\"\"Calculate the accuracy on the test set\"\"\"\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "    print(f\"Test accuracy: {test_acc}\")\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and visualize Pipeline\n",
    "A pipeline is defined with the @pipeline decorator. This defines the various steps of the pipeline and specifies the dependencies between the steps, thereby determining the order in which they will be run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def digits_pipeline(\n",
    "    importer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    model = trainer(X_train=X_train, y_train=y_train)\n",
    "    evaluator(X_test=X_test, y_test=y_test, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize the pipeline\n",
    "first_pipeline = digits_pipeline(\n",
    "    importer=importer(),\n",
    "    trainer=svc_trainer(),\n",
    "    evaluator=evaluator(),\n",
    ")\n",
    "first_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again use the lineage visualizer to see what just happened. The integration will visualize the pipeline run for us right in the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.dash.visualizers.pipeline_run_lineage_visualizer import (\n",
    "    PipelineRunLineageVisualizer,\n",
    ")\n",
    "from zenml.repository import Repository\n",
    "\n",
    "repo = Repository()\n",
    "p = repo.get_pipeline('digits_pipeline')\n",
    "run = p.runs[-1]\n",
    "steps = run.steps\n",
    "s = steps[-1]\n",
    "PipelineRunLineageVisualizer().visualize(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Drift Detection with Evidently\n",
    "\n",
    "Evidently is an open source tool that allows you to easily compute drift on your data. [Here](https://blog.zenml.io/zenml-loves-evidently/) is a little blog post of ours that explains the evidently integration in a bit more detail. \n",
    "\n",
    "At its core, Evidently’s drift detection calculation functions take in a reference data set and compare it with a separate comparison dataset. These are both passed in as Pandas dataframes, though CSV inputs are also possible. ZenML implements this functionality in the form of several standardized steps along with an easy way to use the visualization tools also provided along with Evidently as ‘Dashboards’.\n",
    "\n",
    "\n",
    "If you’re working on any kind of machine learning problem that has an ongoing training loop that takes in new data, you’ll want to guard against drift. Machine learning pipelines are built on top of data inputs, so it is worth checking for drift if you have a model that was trained on a certain distribution of data. The incoming data is something you have less control over and since things often change out in the real world, you should have a plan for knowing when things have shifted. Evidently offers a [growing set of features](https://github.com/evidentlyai/evidently) that help you monitor not only data drift but other key aspects like target drift and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Evidently](_assets/zenml+evidently.png \"Evidently\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a new pipeline with drift detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pipeline2](_assets/chapter_1/second_pipeline.png \"Pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(enable_cache=False)\n",
    "def digits_pipeline_with_drift(\n",
    "    importer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "    \n",
    "    get_reference_data,\n",
    "    drift_detector,\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    model = trainer(X_train=X_train, y_train=y_train)\n",
    "    evaluator(X_test=X_test, y_test=y_test, model=model)\n",
    "    \n",
    "    reference, comparison = get_reference_data(X_train, X_test)\n",
    "    drift_detector(reference, comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the standard evidently step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.evidently.steps import (\n",
    "    EvidentlyProfileConfig,\n",
    "    EvidentlyProfileStep,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def get_reference_data(\n",
    "    X_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    ") -> Output(reference=pd.DataFrame, comparison=pd.DataFrame):\n",
    "    \"\"\"Splits data for drift detection.\"\"\"\n",
    "    # X_train = _add_awgn(X_train)\n",
    "    columns = [str(x) for x in list(range(X_train.shape[1]))]\n",
    "    return pd.DataFrame(X_test, columns=columns), pd.DataFrame(X_train, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and visualize the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidently_profile_config = EvidentlyProfileConfig(\n",
    "    column_mapping=None,\n",
    "    profile_sections=[\"datadrift\"])\n",
    "\n",
    "second_pipeline = digits_pipeline_with_drift(\n",
    "    importer=importer(),\n",
    "    trainer=svc_trainer(),\n",
    "    evaluator=evaluator(),\n",
    "    \n",
    "    # EvidentlyProfileStep takes reference_dataset and comparison dataset\n",
    "    get_reference_data=get_reference_data(),\n",
    "    drift_detector=EvidentlyProfileStep(config=evidently_profile_config)\n",
    ")\n",
    "second_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from zenml.integrations.evidently.visualizers import EvidentlyVisualizer\n",
    "from zenml.repository import Repository\n",
    "import json\n",
    "\n",
    "repo = Repository()\n",
    "p = repo.get_pipeline('digits_pipeline_with_drift')\n",
    "last_run = p.runs[-1]\n",
    "\n",
    "drift_detection_step = last_run.get_step(\n",
    "    name=\"drift_detector\"\n",
    ")\n",
    "evidently_outputs = drift_detection_step\n",
    "\n",
    "EvidentlyVisualizer().visualize(evidently_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add alerts with Discord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLOps promotes giving more visibility to your team about runs of pipelines. A good way to do that is to add a ChatOps step to your pipeline to ping some relevant results every time the pipeline is run. You can use a Discord webhook in your step for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Discord](_assets/evidently+discord.png \"Discord\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an alerter step in your pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pipeline3](_assets/chapter_1/third_pipeline.png \"Pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def digits_pipeline_with_drift_alert(\n",
    "    importer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "    \n",
    "    get_reference_data,\n",
    "    drift_detector,\n",
    "    \n",
    "    alerter,\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    model = trainer(X_train=X_train, y_train=y_train)\n",
    "    evaluator(X_test=X_test, y_test=y_test, model=model)\n",
    "    \n",
    "    reference, comparison = get_reference_data(X_train, X_test)\n",
    "    drift_report, _ = drift_detector(reference, comparison)\n",
    "    \n",
    "    alerter(drift_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a discord alerter step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from zenml.steps import step\n",
    "from zenml.environment import Environment\n",
    "\n",
    "# This is a private ZenML Discord channel. We will get notified if you use \n",
    "# this, but you won't be able to see it. Feel free to create a new Discord \n",
    "# [webhook](https://support.discord.com/hc/en-us/articles/228383668-Intro-to-Webhooks) \n",
    "# and replace this one!\n",
    "DISCORD_URL = (\n",
    "    \"https://discord.com/api/webhooks/935835443826659339/Q32jTwmqc\"\n",
    "    \"GJAUr-r_J3ouO-zkNQPchJHqTuwJ7dK4wiFzawT2Gu97f6ACt58UKFCxEO9\"\n",
    ")\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def discord_alert(\n",
    "    drift_report: dict\n",
    ") -> None:\n",
    "    \"\"\"Send a message to the discord channel to report drift.\n",
    "    Args:\n",
    "        deployment_decision: True if drift detected; false otherwise.\n",
    "    \"\"\"\n",
    "    drift = drift_report[\"data_drift\"][\"data\"][\"metrics\"][\"dataset_drift\"]\n",
    "    url = DISCORD_URL\n",
    "    \n",
    "\n",
    "    env = Environment().step_environment\n",
    "    env.pipeline_name, env.pipeline_run_id, env.step_name\n",
    "    \n",
    "    content = f\"Message from pipeline: **{env.pipeline_name}**, run: **{env.pipeline_run_id}**, step: **{env.step_name}**\"\n",
    "    content += \"\\n\\n\"\n",
    "    content += \"Drift Detected!\" if drift else \"No Drift Detected!\"\n",
    "    \n",
    "    data = {\n",
    "        \"content\": content,\n",
    "        \"username\": \"Drift Bot\",\n",
    "    }\n",
    "    result = requests.post(url, json=data)\n",
    "\n",
    "    try:\n",
    "        result.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(err)\n",
    "    else:\n",
    "        print(\n",
    "            \"Posted to discord successfully, code {}.\".format(\n",
    "                result.status_code\n",
    "            )\n",
    "        )\n",
    "    print(\"Drift detected\" if drift else \"No Drift detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evidently_profile_config = EvidentlyProfileConfig(\n",
    "    column_mapping=None,\n",
    "    profile_sections=[\"datadrift\"])\n",
    "\n",
    "third_pipeline = digits_pipeline_with_drift_alert(\n",
    "    importer=importer(),\n",
    "    trainer=svc_trainer(),\n",
    "    evaluator=evaluator(),\n",
    "    \n",
    "    # EvidentlyProfileStep takes reference_dataset and comparison dataset\n",
    "    get_reference_data=get_reference_data(),\n",
    "    drift_detector=EvidentlyProfileStep(config=evidently_profile_config),\n",
    "    \n",
    "    # Add discord\n",
    "    alerter=discord_alert()\n",
    ")\n",
    "third_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track experiments and parameters with MLFlow\n",
    "\n",
    "For this pipeline we want to take you a step further by showing you some more integrations. We will be using MLFlow Tracking for visualizing and comparing multiple pipeline runs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLflow](_assets/evidently+discord+mlflow.png \"MLflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a trainer with mlflow logging\n",
    "\n",
    "Now that we have mlflow enabled we need to choose what we want to log into mlflow. For now, we have chosen to use the [mlflow autolog](https://www.mlflow.org/docs/latest/tracking.html#scikit-learn) functionality to automatically log the model and training parameters within the training step.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> The @enable_mlflow decorator above the step is all we need to get started with mlflow. This decorator sets up an mlflow experiment and an mlflow backend for all runs within this pipeline. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pipeline4](_assets/chapter_1/fourth_pipeline.png \"Pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.mlflow.mlflow_step_decorator import enable_mlflow\n",
    "import mlflow\n",
    "\n",
    "\n",
    "@enable_mlflow\n",
    "@step(enable_cache=False)\n",
    "def svc_trainer_mlflow(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train another simple sklearn classifier for the digits dataset.\"\"\"\n",
    "    mlflow.sklearn.autolog()\n",
    "    model = SVC(gamma=0.001)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_pipeline = digits_pipeline_with_drift_alert(\n",
    "    importer=importer(),\n",
    "    trainer=svc_trainer_mlflow(),\n",
    "    evaluator=evaluator(),\n",
    "    \n",
    "    # EvidentlyProfileStep takes reference_dataset and comparison dataset\n",
    "    get_reference_data=get_reference_data(),\n",
    "    drift_detector=EvidentlyProfileStep(config=evidently_profile_config),\n",
    "    \n",
    "    # Add discord\n",
    "    alerter=discord_alert()\n",
    ")\n",
    "fourth_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use native mlflow features\n",
    "\n",
    "Training is done, let's have a look at our mlflow ui and see if our training including the model have made it in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will start a serving process for mlflow \n",
    "#  - if you want to continue in the notebook you need to manually\n",
    "#  interrupt the kernel \n",
    "from zenml.integrations.mlflow.mlflow_utils import get_tracking_uri\n",
    "!mlflow ui --backend-store-uri=\"{get_tracking_uri()}\" --port=4997"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create another trainer with a different model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pipeline1](_assets/chapter_1/fixth_pipeline.png \"Pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@enable_mlflow\n",
    "@step(enable_cache=False)\n",
    "def tree_trainer_with_mlflow(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train another simple sklearn classifier for the digits dataset.\"\"\"\n",
    "    mlflow.sklearn.autolog()\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifth_pipeline = digits_pipeline_with_drift_alert(\n",
    "    importer=importer(),\n",
    "    trainer=tree_trainer_with_mlflow(),\n",
    "    evaluator=evaluator(),\n",
    "    \n",
    "    # EvidentlyProfileStep takes reference_dataset and comparison dataset\n",
    "    get_reference_data=get_reference_data(),\n",
    "    drift_detector=EvidentlyProfileStep(config=evidently_profile_config),\n",
    "    \n",
    "    # Add discord\n",
    "    alerter=discord_alert()\n",
    ")\n",
    "fifth_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will start a serving process for mlflow \n",
    "#  - if you want to continue in the notebook you need to manually\n",
    "#  interrupt the kernel \n",
    "from zenml.integrations.mlflow.mlflow_utils import get_tracking_uri\n",
    "!mlflow ui --backend-store-uri=\"{get_tracking_uri()}\" --port=4997"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Continuous Deployment to your ML pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pipeline5](_assets/chapter_1/sixth_pipeline.png \"Pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(enable_cache=False)\n",
    "def continuous_deployment_pipeline_notebook(\n",
    "    importer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "    get_reference_data,\n",
    "    drift_detector,\n",
    "    alerter,\n",
    "    \n",
    "    deployment_trigger,\n",
    "    model_deployer,\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    model = trainer(X_train=X_train, y_train=y_train)\n",
    "    evaluator(X_test=X_test, y_test=y_test, model=model)\n",
    "    \n",
    "    reference, comparison = get_reference_data(X_train, X_test)\n",
    "    drift_report, _ = drift_detector(reference, comparison)\n",
    "    \n",
    "    alerter(drift_report)\n",
    "    \n",
    "    # new \n",
    "    deployment_decision = deployment_trigger(drift_report)\n",
    "    model_deployer(deployment_decision, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define deployment trigger and deployer step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def deployment_trigger(\n",
    "    drift_report: dict,\n",
    ") -> bool:\n",
    "    \"\"\"Implements a simple model deployment trigger that looks at the\n",
    "    drift report and deploys if there's none\"\"\"\n",
    "\n",
    "    drift = drift_report[\"data_drift\"][\"data\"][\"metrics\"][\"dataset_drift\"]\n",
    "\n",
    "    if drift:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from zenml.integrations.mlflow.steps import mlflow_model_deployer_step, MLFlowDeployerConfig\n",
    "\n",
    "model_deployer_ml = mlflow_model_deployer_step\n",
    "\n",
    "\n",
    "sixth_pipeline = continuous_deployment_pipeline_notebook(\n",
    "    importer=importer(),\n",
    "    trainer=tree_trainer_with_mlflow(),\n",
    "    evaluator=evaluator(),\n",
    "    \n",
    "    # EvidentlyProfileStep takes reference_dataset and comparison dataset\n",
    "    get_reference_data=get_reference_data(),\n",
    "    drift_detector=EvidentlyProfileStep(config=evidently_profile_config),\n",
    "    \n",
    "    # Add discord\n",
    "    alerter=discord_alert(),\n",
    "    \n",
    "    deployment_trigger=deployment_trigger(),\n",
    "    model_deployer=model_deployer_ml(config=MLFlowDeployerConfig(workers=1)),\n",
    ")\n",
    "sixth_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interact with deployed model service directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml served-models list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.repository import Repository\n",
    "\n",
    "repo = Repository()\n",
    "p = repo.get_pipeline('continuous_deployment_pipeline_notebook')\n",
    "last_run = p.runs[-1]\n",
    "X_test = last_run.steps[0].outputs['X_test'].read()\n",
    "y_test = last_run.steps[0].outputs['y_test'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deployer = repo.active_stack.model_deployer\n",
    "services = model_deployer.find_model_server(\n",
    "    pipeline_name=\"continuous_deployment_pipeline_notebook\",\n",
    "    pipeline_step_name=\"mlflow_model_deployer_step\",\n",
    "    running=True,\n",
    ")\n",
    "service = services[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.check_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0], y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "service.predict(X_test[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ax.set_axis_off()\n",
    "plt.imshow(X_test[0].reshape(8, 8), cmap=plt.cm.gray_r, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Continuous Inference pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch data in real time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLflow](_assets/ZenML0-6-2.gif \"ZenML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_api():\n",
    "    data = np.array([[ 0.,  0.,  1., 11., 14., 15.,  3.,  0.,  0.,  1., 13., 16., 12.,\n",
    "        16.,  8.,  0.,  0.,  8., 16.,  4.,  6., 16.,  5.,  0.,  0.,  5.,\n",
    "        15., 11., 13., 14.,  0.,  0.,  0.,  0.,  2., 12., 16., 13.,  0.,\n",
    "         0.,  0.,  0.,  0., 13., 16., 16.,  6.,  0.,  0.,  0.,  0., 16.,\n",
    "        16., 16.,  7.,  0.,  0.,  0.,  0., 11., 13., 12.,  1.,  0.]])\n",
    "    # data = np.array([x.reshape(1, 8, 8) for x in data])\n",
    "    return data\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def dynamic_importer() -> Output(data=np.ndarray):\n",
    "    \"\"\"Downloads the latest data from a mock API.\"\"\"\n",
    "    data = get_data_from_api()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the latest deployed model and run inference on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.steps import BaseStepConfig\n",
    "from zenml.services import BaseService\n",
    "\n",
    "class PredictionServiceLoaderStepConfig(BaseStepConfig):\n",
    "    \"\"\"Model deployment service loader configuration\n",
    "\n",
    "    Attributes:\n",
    "        pipeline_name: name of the pipeline that deployed the model prediction\n",
    "            server\n",
    "        step_name: the name of the step that deployed the model prediction\n",
    "            server\n",
    "        model_name: the name of the model that was deployed\n",
    "    \"\"\"\n",
    "\n",
    "    pipeline_name: str\n",
    "    step_name: str\n",
    "    model_name: str\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def prediction_service_loader(\n",
    "    config: PredictionServiceLoaderStepConfig,\n",
    ") -> BaseService:\n",
    "    \"\"\"Get the prediction service started by the deployment pipeline\"\"\"\n",
    "\n",
    "    model_deployer = Repository(skip_repository_check=True).active_stack.model_deployer\n",
    "    if not model_deployer:\n",
    "        raise RuntimeError(\n",
    "            \"No Model Deployer was found in the active stack.\"\n",
    "        )\n",
    "\n",
    "    services = model_deployer.find_model_server(\n",
    "        pipeline_name=config.pipeline_name,\n",
    "        pipeline_step_name=config.step_name,\n",
    "        model_name=config.model_name,\n",
    "    )\n",
    "    if not services:\n",
    "        raise RuntimeError(\n",
    "            f\"No model prediction server deployed by the \"\n",
    "            f\"'{config.step_name}' step in the '{config.pipeline_name}' \"\n",
    "            f\"pipeline for the '{config.model_name}' model is currently \"\n",
    "            f\"running.\"\n",
    "        )\n",
    "\n",
    "    if not services[0].is_running:\n",
    "        raise RuntimeError(\n",
    "            f\"The model prediction server last deployed by the \"\n",
    "            f\"'{config.step_name}' step in the '{config.pipeline_name}' \"\n",
    "            f\"pipeline for the '{config.model_name}' model is not currently \"\n",
    "            f\"running.\"\n",
    "        )\n",
    "\n",
    "    return services[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@step\n",
    "def predictor(\n",
    "    service: BaseService,\n",
    "    data: np.ndarray,\n",
    ") -> Output(predictions=list):\n",
    "    \"\"\"Run a inference request against a prediction service\"\"\"\n",
    "    service.start(timeout=10)  # should be a NOP if already started\n",
    "    prediction = service.predict(data)\n",
    "    prediction = prediction.argmax(axis=-1)\n",
    "    print(f\"Prediction is: {[prediction.tolist()]}\")\n",
    "    return [prediction.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the CI pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def inference_pipeline(\n",
    "    dynamic_importer,\n",
    "    prediction_service_loader,\n",
    "    predictor,\n",
    "):\n",
    "    # Link all the steps artifacts together\n",
    "    batch_data = dynamic_importer()\n",
    "    model_deployment_service = prediction_service_loader()\n",
    "    predictor(model_deployment_service, batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an inference pipeline run\n",
    "inference = inference_pipeline(\n",
    "    dynamic_importer=dynamic_importer(),\n",
    "    prediction_service_loader=prediction_service_loader(\n",
    "        PredictionServiceLoaderStepConfig(\n",
    "            pipeline_name=\"continuous_deployment_pipeline_notebook\",\n",
    "            step_name=\"mlflow_model_deployer_step\",\n",
    "            model_name=\"model\",\n",
    "        )\n",
    "    ),\n",
    "    predictor=predictor(),\n",
    ")\n",
    "\n",
    "inference.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
